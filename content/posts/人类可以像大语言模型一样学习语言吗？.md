---
author: 剩翼
categories:
- 随笔
collections:
- 心影抄
- 翼说
date: 2025-07-08
draft: false
lastmod: 2025-07-10
summary: 没有人愿意失去语言背后的意义世界而只想将语言说得在别人听起来很好、很出色。人类的语言背后总是关涉着存在，我们说话，存在就在话语中展开；我们交谈，彼此的存在就在交谈中展开。
tags:
- 心灵哲学
- 哲学
- AI
- 心理
title: 人类可以像大语言模型一样学习语言吗？
---

![](/img/AIlanguage.jpg)

人类学习语言的过程与大语言模型（如 GPT-4）的学习过程在某些方面有相似之处，但也存在显著的不同。

## 相似之处

1.  **输入和输出**：人类学习语言需要接触大量的语言输入（听、说、读、写），大语言模型也是通过大量文本数据进行训练。两者都依赖于输入来生成语言输出。

2.  **模式识别**：人类在学习语言时会识别语法、词汇、语音等方面的模式。大语言模型通过机器学习算法能够识别并生成语言中的各种模式。

3.  **反馈机制**：人类在交流中会获得反馈（如纠正错误或增强理解），而大语言模型则通过对训练数据的反复学习和优化参数来改进其输出。

## 不同之处

1.  **学习方式**：人类的语言学习通常是通过自然的社交互动、模仿和情境学习等方式进行的，而大语言模型则是通过处理大量的数据集，依赖于统计方法和算法优化。

2.  **理解和意识**：人类在学习语言时，不仅仅是机械地模仿，而是能够理解语言的意义、情感和语境。大语言模型在生成语言时并没有真正的理解能力，它只是根据概率生成最符合上下文的词语。

3.  **文化和主观体验**：人类的语言学习与文化背景、个人经历以及情感密切相关，这些因素会影响语言的使用和理解。而大语言模型缺乏这种文化和主观体验，它的输出是基于训练数据中的统计特征。

4.  **学习的灵活性和适应性**：人类能够主动学习、适应新环境和新情况，而大语言模型的学习是静态的，一旦训练完成，就无法通过新经验主动改变。

## 结论

综上所述，人可以像大语言模型一样在某种程度上学习语言，但人类的学习过程更为复杂和深刻，涉及理解、文化和情感等多重因素，而大语言模型则更依赖于数据和统计规律。因此，尽管两者在某些方面有相似之处，但本质上是不同的学习机制。

**以上是 ChatGPT （GPT-4 o-mini）对文题的回答。**

已经回答得很全面细致了。但还值得人来罗嗦两句：

## 大语言模型掌握了什么？

### 维特根斯坦："用法即意义"

这是维特根斯坦的主张。在当年，说是里程碑式的主张并不为过。而今，熟悉语言哲学的人对这一观念自是不觉新鲜，但普通人，未必明白是什么意思。

说起来也倒简单，基本上就是语言，或者说一个词、一个句子，用得合适、用对了情境，就实现了语言的意义。**如此就好，不必非得知道这些词句代表的意思 [^1]，或者说它们指称什么。**

**如果语言就是这样一种东西，** 那就意味着，我们其实可以想象一种"空心人"，他与人类具有相同分子结构、生理反应及行为模式，说着和我们同样的话语，但没有与人一样的心灵，完全没有话语背后的任何意识，当然也不明白这些话语的意思。

这里叫这种假想生物"空心人"只是为了响应本文主题。实际上大卫•查尔默斯 [^2] 已经提出了这个思想实验，在他那里，这种生物被叫做"哲学僵尸"。

### 塞尔："中文屋"

对上述原理更为形象的摹画来自美国哲学家塞尔 [^3] 。20 世纪 80 年代，他提出的名为"中文屋"的思想实验早在 40 多年前已经给出了现今大语言模型的示意图：

想象一位只会说英语的人身处一个房间之中，除了门上有一个小窗口外，屋子是全封闭的。屋子里有一本神奇的书，书中记载着所有中文语句的所有恰当回复。屋里还有足够的纸笔。屋外人将写着中文的纸片通过小窗口被送入屋中。屋中人在书中找到回复，写（画）下来，回复屋外的人。如此，双方无障碍交流，屋内人尽管并不会说中文（当然也不知道这些词句的中文意思），却可以让屋外的人以为他会说中文。

这个思想实验，是塞尔为了反驳图灵测试 [^4] 而提出的。塞尔至今认为，机器永远也不可能真正的理解接收到的信息，它们只能给人一种智能的印象，尽管这种印象可以达到乱真的程度。

从塞尔深具预见性的寓言可以看到，AI 就是那个掌握了"神奇问答之书"的人，大语言模型可以视为"中文屋"的现实版。

稍稍了解大语言模型工作原理的人都知道，AI 并不知道它所说出词句的意思，它是通过语言"横向"连缀的概率来计算一个词后面跟随哪个词更合适来连缀句子和段落，从而"说话"的。

而在这里，我们又发现了比塞尔更早的先见之明：大语言模型掌握的恰恰是维特根斯坦称为"用法"的东西。在某种意义上，我们能说，且只能说，AI 会 **"用"** 语言。

## 人与大语言模型的差异

### 丹尼特的质疑

丹尼尔•丹尼特 [^5] 曾对塞尔的"中文屋"提出质疑，他提出，如果屋外人的问题是"你上次说的话是什么？"，屋内的人可能很难准确回答。

有趣的是，丹尼特的质疑也恰好是大语言模型发展初期的一个问题。那就是 AI 似乎记忆力不是特别好，虽然还没到记不住上次自己的回答的程度，但如果主题不够集中，你问题里引用的内容又与之前的内容相隔较远，它可能是会出错。现在，这种现象在模型优化后有了很大改善。然而，这种改善并不是说 AI 有了**人一般的**记忆，而是将一定数量的上下文纳入了学习。

### 假装

AI 始终有一个难以解决的"幻觉"问题，也就是它会为回答它没有学习过的问题而编故事。尤其是你的问题如果是"关公战秦琼"式的，幻觉率貌似更高；如果可以联网的话，幻觉率会大大降低，然而并不能实现完全消除。这种改善**仍旧**不是说 AI 有了**人一般的**记忆，而是将更多内容纳入了学习。

其实这也不难理解。我们就是在"语义不符合现实"这样的意思上使用"幻觉"这个词的。如果大语言模型只是**使用语言，** 而并**不把它的语言和现实联系，** 幻觉是不可能彻底消除的。

此外，"幻觉"的存在还提示一个重要意义，那就是，大语言模型似乎真的是 **"一张白纸"** ，你让它学习什么，它便学习什么。这同样是"幻觉"产生的一个因素。今年伊始被国人捧上天的 DeepSeek，幻觉率非常高，尤其是新闻实事类问题，什么原因，也不必说了。

丹尼特的质疑和所谓的"幻觉"，**根底处**都是来源于 AI 并不 **"真懂"** 它说出的那些话。然而人却并不一样，**人并不是靠记住各种字词的组合概率来学习语言的，** 人的语言背后**总是关联着存在，** 因此人总是对语言有 **"真假意识"**，但 AI 没有。

人也会编故事，也会说谎。但人编的故事和 AI 编的故事却不一样，不是看起来不一样------可能 AI 编造的故事，逻辑上甚至更加完美。差别是是本质上的：**人即使在假装，仍然具有与这种假装相应的意识。**

简言之，**人的语言总是和某种心灵状态相伴随的，** 说真话时，和某种真话状态相伴随；说假话时，和某种假话状态相伴随；说半真半假的话时，和半真半假的状态相伴随。

如果人不具备这种状态，那么人就说不出任何话。语言之于人，也没有任何意义。

实际上，人如果一开始就没有意识，没有欲望、信念、思维、体验，那么我们的确也不需要什么假装，但果如此，人为什么需要语言，为什么需要说话呢？

## 人，语言，存在

### 像与象

人无法**靠 AI 的方式**来习得语言，这本来是很显然的事实。容易想象，如果人不是通过某种方式**将语言和世间的事物与事态相关联，** 而仅仅依靠熟记各种语词之间排列组合的概率、却根本不晓得语词的任何含义，是绝不可能的。

**人不可能仅仅依靠熟记能指和能指的各种组合态来学会语言，人必须靠将能指和所指连在一起来学习语言。** AI 之所以可以不管什么所指，也能将话讲得和人一样好，主要是**在算力上完全可以支撑**这种模式------这是人无论怎么开发大脑，都无法做到的。

人必须通过语言与存在的**关涉**来学习语言。虽然并不是"指物定义"那样简单，但人仍会在不断地学习与使用中学会以某种 **"象"** 的方式联系语词和存在，或者说，人学习语言就是一个不断将语言和存在关联的过程。

比如，我们听到听到"兔子"这个词，意识中会有一只兔子，但却不是固定的哪一只兔子，也并不一定就是黑兔、白兔、灰兔、漫画书上的兔子......，同样也无需将这个"象"言说清楚，只要我们意识中这个"象"，可以将兔子这个字词和兔子的所指联系在一起就可以了。

人学习语言，就是这样一个将字词与存在相关联的过程，一个建立 **"象"** 的网络的过程。而 AI 则是不断地奔向 **"像"** 的目标的过程，它将模仿人言作为目标，它也将越来越像（人说话）。

### 语言是存在的家

人可以像大语言模型一样学习语言吗？实话说，这个问题有些无聊。然而，想一想一些疯子构想的脑后插管的未来，又有必要对此做些澄清，因为这些疯狂的构想至少部分考虑是基于学习（或者说信息传递）广度和效率的。

人如果可以像大语言模型一样学习语言，固然可以提高语言的学习效率，但**没有人愿意失去语言背后的意义世界而只想将语言说得在别人听起来很好、很出色。**

我们说话，总是怀着某种希望的。我们希望表达出某种东西，并且希望听者也可以借助我们的话语抵达那些东西。**我们说话，存在就在话语中展开；我们交谈，彼此的存在就在交谈中展开。** 通过这种方式，语言始终与存在一体，始终与我们的意义相关。

**语言，理应只能在一个相当相当狭窄的意义上，被视为一种工具。语言是存在的家。** 没有语言，所谓存在，包括这个"我"，便无处安放，或者便不存在，或者，在与不在都无所谓，与人无关。通过大语言模型的横空出世，人应该可以意识到，**恰恰是人的这种"有限"配置，保障着人"在世存在"的意义。**

如果我们把问题改做：大语言模型可以像人一样学习语言吗？而答案竟然是"是"，那便很有趣了，突破这个壁垒， AI 可能真的会成为一种类人的生物，那时，AI 也就有了世界，那时的 AI 便不再是学习语言，而真正像人一样言说，像人一样存在；那时，人们对 AI 的期待也不再是让 AI 认识世界，因为它已经像人一样**在世界之中存在。**



[^1]: 由于中文中"意义"有多个意思，"意义"与"意思"常混用，比如我们也常问"这个词的意义是什么？"而这里问的往往是这个词的指称。故而这里用"意思"代表指称，而意义专指维特根斯坦强调的"用法"。

[^2]: 大卫·查尔默斯（David Chalmers, 1966-），现任澳大利亚国立大学脑意识研究中心主任、哲学教授及纽约大学哲学教授，心灵哲学家。

[^3]: 约翰·塞尔（J.R.Searle, 1932-）当今世界最著名、最具影响力的哲学家之一，执教于加州大学伯克利分校。

[^4]: 图灵测试意指如果一个人工智能机能够使被参与测试的 30% 的人产生误判（与他对话的是人类），这个机器就拥有了智能。

[^5]: 丹尼尔·丹尼特（Daniel Dennett, 1942-2024）是当代最具影响力的哲学家与认知科学家之一，生前长期担任塔夫茨大学哲学教授及认知科学研究中心主任。
